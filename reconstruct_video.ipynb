{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bfa890-887b-4644-89e1-7e1f2fe15798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Extracting frames...\n",
      "  extracted 300 frames to frames_improved\n",
      "2) Extracting CNN features on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\RITANKAR/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:03<00:00, 12.2MB/s]\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:16<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  features shape: (300, 512)\n",
      "3) Pairwise similarity (cosine distance)...\n",
      "4) Phase-correlation shifts (direction cues)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing phase-correlation shifts: 100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [03:01<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inferred median forward shift: [1. 0.]\n",
      "5) Building directed cost matrix...\n",
      "6) Reconstructing order with beam search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beam search ordering: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 299/299 [00:00<00:00, 4059.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7) Writing reconstructed video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing output video: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:11<00:00, 26.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done — reconstructed saved to reconstructed_improved.mp4 (time 236.82s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from math import inf\n",
    "\n",
    "# ---------- Parameters ----------\n",
    "VIDEO_PATH = \"jumbled_video.mp4\"\n",
    "FRAMES_DIR = \"frames_improved\"\n",
    "OUTPUT_VIDEO = \"reconstructed_improved.mp4\"\n",
    "FPS = 30\n",
    "IMG_SIZE = 224             # for CNN embedding\n",
    "BEAM_WIDTH = 6             # larger -> slower but more robust (try 4..12)\n",
    "DIRECTION_WEIGHT = 0.35    # how strongly direction influences cost (0..1)\n",
    "# -------------------------------\n",
    "\n",
    "def extract_frames(video_path, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imwrite(os.path.join(out_dir, f\"frame_{idx:04d}.jpg\"), frame)\n",
    "        idx += 1\n",
    "    cap.release()\n",
    "    return idx\n",
    "\n",
    "def get_resnet_feature_extractor(device):\n",
    "    \n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    modules = list(model.children())[:-1]  \n",
    "    model = nn.Sequential(*modules)\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "def extract_features_gpu(frames_dir, device):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std =[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    files = sorted(os.listdir(frames_dir))\n",
    "    feats = []\n",
    "    model = get_resnet_feature_extractor(device)\n",
    "    with torch.no_grad():\n",
    "        for f in tqdm(files, desc=\"Extracting features\"):\n",
    "            img = Image.open(os.path.join(frames_dir, f)).convert(\"RGB\")\n",
    "            t = transform(img).unsqueeze(0).to(device)\n",
    "            out = model(t)            # shape: (1, 512, 1, 1)\n",
    "            out = out.squeeze().cpu().numpy().reshape(-1)\n",
    "            feats.append(out)\n",
    "    feats = np.vstack(feats)\n",
    "\n",
    "    norms = np.linalg.norm(feats, axis=1, keepdims=True)\n",
    "    feats = feats / (norms + 1e-10)\n",
    "    return files, feats\n",
    "\n",
    "def compute_pairwise_cosine_distance(feats):\n",
    "   \n",
    "    sims = feats @ feats.T\n",
    "    dists = 1.0 - sims\n",
    "    np.fill_diagonal(dists, inf)\n",
    "    return dists\n",
    "\n",
    "def phase_correlation_shift(grayA, grayB):\n",
    "   \n",
    "    a = np.float32(grayA)\n",
    "    b = np.float32(grayB)\n",
    "   \n",
    "    hann = cv2.createHanningWindow(a.shape[::-1], cv2.CV_32F)\n",
    "    a_win = a * hann\n",
    "    b_win = b * hann\n",
    "    shift, response = cv2.phaseCorrelate(a_win, b_win)\n",
    "   \n",
    "    return np.array(shift), response\n",
    "\n",
    "def compute_direction_matrix(frames_dir, frame_files, use_downscale=(640,360)):\n",
    "    n = len(frame_files)\n",
    "    shifts = np.zeros((n, n, 2), dtype=np.float32)\n",
    "    responses = np.zeros((n,n), dtype=np.float32)\n",
    "  \n",
    "    gray_list = []\n",
    "    for f in frame_files:\n",
    "        img = cv2.imread(os.path.join(frames_dir, f))\n",
    "        h,w = img.shape[:2]\n",
    "        if use_downscale:\n",
    "            img = cv2.resize(img, use_downscale, interpolation=cv2.INTER_LINEAR)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_list.append(gray)\n",
    "    for i in tqdm(range(n), desc=\"Computing phase-correlation shifts\"):\n",
    "        a = gray_list[i]\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                shifts[i,j] = (0.0,0.0)\n",
    "                responses[i,j] = 0.0\n",
    "            else:\n",
    "                s, r = phase_correlation_shift(a, gray_list[j])\n",
    "                shifts[i,j] = s\n",
    "                responses[i,j] = r\n",
    "    return shifts, responses\n",
    "\n",
    "def infer_global_forward(shifts, responses, mask_threshold=0.0001):\n",
    "   \n",
    "    n = shifts.shape[0]\n",
    "    flat_shifts = shifts.reshape(-1,2)\n",
    "    flat_resp = responses.reshape(-1)\n",
    "    \n",
    "    sel = flat_resp > np.percentile(flat_resp, 60) \n",
    "    if sel.sum() == 0:\n",
    "        sel = flat_resp > np.mean(flat_resp)\n",
    "    if sel.sum() == 0:\n",
    "       \n",
    "        median = np.median(flat_shifts, axis=0)\n",
    "    else:\n",
    "        median = np.median(flat_shifts[sel], axis=0)\n",
    "    \n",
    "    if np.linalg.norm(median) < 0.3:\n",
    "        median = np.array([1.0, 0.0])\n",
    "    return median\n",
    "\n",
    "def build_directed_cost_matrix(sim_dists, shifts, median_forward, responses, direction_weight):\n",
    "   \n",
    "    n = sim_dists.shape[0]\n",
    "    cost = sim_dists.copy()\n",
    "    \n",
    "    med = median_forward / (np.linalg.norm(median_forward) + 1e-9)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j:\n",
    "                cost[i,j] = inf\n",
    "                continue\n",
    "            shift = shifts[i,j]\n",
    "            proj = float(np.dot(shift, med)) \n",
    "            resp = responses[i,j]\n",
    "            \n",
    "            dir_score = np.tanh(proj / (np.linalg.norm(shift)+1e-9)) * (resp / (resp + 1.0))\n",
    "            \n",
    "            cost[i,j] = sim_dists[i,j] * (1.0 - direction_weight * dir_score)\n",
    "   \n",
    "    np.fill_diagonal(cost, inf)\n",
    "    return cost\n",
    "\n",
    "def beam_search_order(cost_matrix, beam_width=6):\n",
    "    n = cost_matrix.shape[0]\n",
    "   \n",
    "    row_sums = np.nan_to_num(cost_matrix.sum(axis=1), posinf=1e9)\n",
    "    start_candidates = np.argsort(row_sums)[:min(6, n)]\n",
    "    \n",
    "    beams = []\n",
    "    for s in start_candidates:\n",
    "        beams.append((0.0, [s], set(range(n)) - {s}))\n",
    "    for step in tqdm(range(n-1), desc=\"Beam search ordering\"):\n",
    "        new_beams = []\n",
    "        for total, path, rem in beams:\n",
    "            last = path[-1]\n",
    "            \n",
    "            options = sorted(list(rem), key=lambda j: cost_matrix[last,j])\n",
    "          \n",
    "            k = min(beam_width, len(options))\n",
    "            for next_idx in options[:k]:\n",
    "                new_total = total + float(cost_matrix[last, next_idx])\n",
    "                new_path = path + [next_idx]\n",
    "                new_rem = rem - {next_idx}\n",
    "                new_beams.append((new_total, new_path, new_rem))\n",
    "      \n",
    "        new_beams.sort(key=lambda x: x[0])\n",
    "        beams = [(c, p, r) for (c,p,r) in new_beams[:beam_width]]\n",
    "\n",
    "    best = min(beams, key=lambda x: x[0])\n",
    "    return best[1]\n",
    "\n",
    "def write_video_from_order(frames_dir, frame_files, order, output_path, fps=30):\n",
    "    first = cv2.imread(os.path.join(frames_dir, frame_files[order[0]]))\n",
    "    h,w = first.shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (w,h))\n",
    "    for idx in tqdm(order, desc=\"Writing output video\"):\n",
    "        frame = cv2.imread(os.path.join(frames_dir, frame_files[idx]))\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    print(\"1) Extracting frames...\")\n",
    "    n = extract_frames(VIDEO_PATH, FRAMES_DIR)\n",
    "    print(f\"  extracted {n} frames to {FRAMES_DIR}\")\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"2) Extracting CNN features on device: {device}\")\n",
    "    frame_files, feats = extract_features_gpu(FRAMES_DIR, device)\n",
    "    print(\"  features shape:\", feats.shape)\n",
    "\n",
    "    print(\"3) Pairwise similarity (cosine distance)...\")\n",
    "    sim_dists = compute_pairwise_cosine_distance(feats)\n",
    "\n",
    "    print(\"4) Phase-correlation shifts (direction cues)...\")\n",
    "    shifts, responses = compute_direction_matrix(FRAMES_DIR, frame_files, use_downscale=(512,288))\n",
    "    median_forward = infer_global_forward(shifts, responses)\n",
    "    print(\"  inferred median forward shift:\", median_forward)\n",
    "\n",
    "    print(\"5) Building directed cost matrix...\")\n",
    "    cost = build_directed_cost_matrix(sim_dists, shifts, median_forward, responses, DIRECTION_WEIGHT)\n",
    "\n",
    "    print(\"6) Reconstructing order with beam search...\")\n",
    "    order_indices = beam_search_order(cost, beam_width=BEAM_WIDTH)\n",
    "\n",
    "    print(\"7) Writing reconstructed video...\")\n",
    "    write_video_from_order(FRAMES_DIR, frame_files, order_indices, OUTPUT_VIDEO, fps=FPS)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"\\nDone — reconstructed saved to {OUTPUT_VIDEO} (time {elapsed:.2f}s)\")\n",
    "    with open(\"execution_time_log.txt\", \"w\") as f:\n",
    "        f.write(f\"Execution Time: {elapsed:.2f} seconds\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63f05a-d07f-4e75-b233-9b472c839aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Tecdia)",
   "language": "python",
   "name": "tecdia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
